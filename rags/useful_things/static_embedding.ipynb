{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 400x faster Static Embedding Models with Sentence Transformers\n",
    "\n",
    "- HuggingFace 에서 트랜스포머 없이도 효울적이고 빠른 임베딩 모델을 만들 수 있음을 입증.\n",
    "- Contrastive Learning & Matryoshka Prepresentation Learning 기법이 적용되었음\n",
    "\n",
    "- CPU 에서 기존의 SotA 임베딩 모델보다 100 ~ 400배 가량 빠르게 동작.\n",
    "- 85% 이상의 성능을 유지하며 저전력 장치, 브라우저 내 실행, 엣지 컴퓨팅, 임베디드 애플리케이션에서 유용하게 사용 가능\n",
    "\n",
    "- transformer 가 아닌 고정 벡터 임베딩 모델은 토큰별 임베딩이 존재하지 않음.\n",
    "\n",
    "| 항목               | Transformer 기반 모델                 | Static 임베딩 모델                |\n",
    "| ---------------- | --------------------------------- | ---------------------------- |\n",
    "| 학습 방식            | 딥러닝 기반 (BERT, RoBERTa 등)          | 사전 벡터 테이블 기반                 |\n",
    "| 문맥 정보 사용         | O (다른 단어에 따라 벡터 달라짐)              | X (단어마다 고정된 벡터)              |\n",
    "| 토큰별 임베딩 접근 가능 여부 | ✅ (last\\_hidden\\_state 등으로 접근 가능) | ❌ (내부적으로는 단어 벡터 평균이지만 제공 안함) |\n",
    "| 문장 임베딩 생성 방식     | 풀링 (mean/max/\\[CLS])              | 단어 벡터 평균 또는 학습된 lookup       |\n",
    "| 속도               | 상대적으로 느림                          | 매우 빠름                        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![성능 보고](https://discuss.pytorch.kr/uploads/default/original/2X/b/b4ea1f82405f33575fcb0e9927b873b0519c22c0.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 영어 전용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding_result:\n",
      "[[ 0.88718474  1.5768831   0.69887877 ... -0.24080743 -1.4645687\n",
      "   2.2299294 ]\n",
      " [ 2.8064165   0.38496497  0.07772089 ... -1.1711209  -3.8380172\n",
      "   0.33326927]\n",
      " [ 0.8913804   1.8343288   3.6360757  ...  0.43299392 -3.136761\n",
      "  -0.74646676]]\n",
      "경과 시간: 0.0010941250002360903 초\n"
     ]
    }
   ],
   "source": [
    "import timeit  # 특정 함수나 코드의 실행시간을 측정하는 방법\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Model Definition\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/static-retrieval-mrl-en-v1\", device=\"cpu\"\n",
    ")\n",
    "\n",
    "\n",
    "def sample_embedding():\n",
    "    sentences = [\n",
    "        \"'리더보드 세계 1위' 업스테이지·모티프, ‘K-AI 모델’ 프로젝트 도전\",\n",
    "        \"구글, 제미나이 '사고 사슬' 은폐로 항의 이어져\",\n",
    "        \"'바이브 코딩'이 SW산업 근간 흔들어...'SaaS에서 자체 개발로 다시 전환'\",\n",
    "    ]\n",
    "    embeddings = model.encode(sentences)\n",
    "    result = embeddings.shape\n",
    "    print(f\"Embedding_result:\\n{embeddings}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "elapsed_time = timeit.timeit(sample_embedding, number=1)\n",
    "print(f\"경과 시간: {elapsed_time} 초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 다국어 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding_result:\n",
      "[[-2.2644203   0.92411804  0.45479402 ... -1.8955355  -0.6589372\n",
      "   3.6921167 ]\n",
      " [ 3.1510851   4.8153977  -0.6599985  ... -2.4062247   2.3244624\n",
      "  -0.13505702]\n",
      " [-0.78002775  2.3598654  -0.22167262 ... -0.4199912  -0.95721096\n",
      "   0.84989446]]\n",
      "경과 시간: 0.0024876250026864 초\n"
     ]
    }
   ],
   "source": [
    "import timeit  # 특정 함수나 코드의 실행시간을 측정하는 방법\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Model Definition\n",
    "model = SentenceTransformer(\n",
    "    \"sentence-transformers/static-similarity-mrl-multilingual-v1\", device=\"cpu\"\n",
    ")\n",
    "\n",
    "\n",
    "def sample_embedding():\n",
    "    sentences = [\n",
    "        \"'리더보드 세계 1위' 업스테이지·모티프, ‘K-AI 모델’ 프로젝트 도전\",\n",
    "        \"구글, 제미나이 '사고 사슬' 은폐로 항의 이어져\",\n",
    "        \"'바이브 코딩'이 SW산업 근간 흔들어...'SaaS에서 자체 개발로 다시 전환'\",\n",
    "    ]\n",
    "    embeddings = model.encode(sentences)\n",
    "    result = embeddings.shape\n",
    "    print(f\"Embedding_result:\\n{embeddings}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "elapsed_time = timeit.timeit(sample_embedding, number=1)\n",
    "print(f\"경과 시간: {elapsed_time} 초\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
